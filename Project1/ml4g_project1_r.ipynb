{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "794f70e9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘xgboost’\n",
      "\n",
      "The following object is masked from ‘package:IRanges’:\n",
      "\n",
      "    slice\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    slice\n",
      "\n",
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "\n",
      "Attaching package: ‘data.table’\n",
      "\n",
      "The following object is masked from ‘package:GenomicRanges’:\n",
      "\n",
      "    shift\n",
      "\n",
      "The following object is masked from ‘package:IRanges’:\n",
      "\n",
      "    shift\n",
      "\n",
      "The following objects are masked from ‘package:S4Vectors’:\n",
      "\n",
      "    first, second\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    between, first, last\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "\n",
    "library(dplyr, quietly = T)\n",
    "library(GenomicRanges, quietly = T)\n",
    "library(foreach, quietly = T)\n",
    "library(xgboost, quietly = T)\n",
    "library(ggplot2, quietly = T)\n",
    "library(data.table, quietly = T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da8ccbe4",
   "metadata": {},
   "source": [
    "Information about data: \n",
    "- CAGE-train (\"data/CAGE-train\"): includes information about gene location and expression. X1 and X2 has train/val info/y, X3 only has test info that we should test on (only testing on chr1). \n",
    "- DNase-seq: information on chromatin accessibility (reads only in open chromatin)\n",
    "- bed, bigwig: genomic regions and associated annotations \n",
    "- do not use H3K9me3, distribution too different among X1, X2, X3 \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "136a6c2f",
   "metadata": {},
   "source": [
    "## Work Package 1.1 - Modeling Choices & Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2971da50",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# bed and bigwig files contain signals of all chromosomes (including sex chromosomes).\n",
    "# Training and validation split based on chromosomes has been done for you. \n",
    "# However, you can resplit the data in any way you want.\n",
    "\n",
    "############################ READ IN DATA ####################################\n",
    "\n",
    "files <- list.files(\"../ML4G_Project_1_Data/\")\n",
    "bed_files <- files[stringr::str_detect(files,\"-bed\")]\n",
    "\n",
    "# Load the beds, join them and convert them to genomic range objects and \n",
    "# store them in a list\n",
    "\n",
    "cell_lines <- c(\"X1\",\"X2\",\"X3\")\n",
    "\n",
    "beds <- list()\n",
    "beds2 <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "142312b9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in .find_start_end_cols(df_colnames0, start.field0, end.field0): cannnot determine start/end columns\n",
     "output_type": "error",
     "traceback": [
      "Error in .find_start_end_cols(df_colnames0, start.field0, end.field0): cannnot determine start/end columns\nTraceback:\n",
      "1. beds[[cell_line]] %>% GenomicRanges::makeGRangesFromDataFrame(keep.extra.columns = T, \n .     seqnames.field = \"V1\", start.field = \"V2\", end.field = \"V3\")",
      "2. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
      "3. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "4. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "5. `_fseq`(`_lhs`)",
      "6. freduce(value, `_function_list`)",
      "7. withVisible(function_list[[k]](value))",
      "8. function_list[[k]](value)",
      "9. GenomicRanges::makeGRangesFromDataFrame(., keep.extra.columns = T, \n .     seqnames.field = \"V1\", start.field = \"V2\", end.field = \"V3\")",
      "10. .find_GRanges_cols(names(df), seqnames.field = seqnames.field, \n  .     start.field = start.field, end.field = end.field, strand.field = strand.field, \n  .     ignore.strand = ignore.strand)",
      "11. .find_start_end_cols(df_colnames0, start.field0, end.field0)",
      "12. stop(\"cannnot determine start/end columns\")"
     ]
    }
   ],
   "source": [
    "for (cell_line in cell_lines) {\n",
    "  temp <- list()\n",
    "  for (bed_file in bed_files) {\n",
    "    \n",
    "    tempII <- data.table::fread(paste0(c(\"../ML4G_Project_1_Data/\",bed_file,\"/\",cell_line,\".bed\"),collapse = \"\"))\n",
    "    \n",
    "    if(bed_file == \"DNase-bed\" ){ \n",
    "      tempII$score <- tempII$V7\n",
    "      tempII$score_scaled <- scale(tempII$V7) + 2\n",
    "    } else {\n",
    "      tempII$score <- tempII$V5\n",
    "      tempII$score_scaled <- scale(tempII$V5) + 2\n",
    "    }\n",
    "\n",
    "    tempII$type <- bed_file\n",
    "    \n",
    "    temp[[bed_file]] <- tempII\n",
    "\n",
    "  }\n",
    "  \n",
    "  beds[[cell_line]] <- data.table::rbindlist(temp) \n",
    "  beds[[cell_line]]$type <- as.factor(  beds[[cell_line]]$type )\n",
    "    \n",
    "  beds2[[cell_line]] <- beds[[cell_line]]\n",
    "  beds2[[cell_line]]$cell_line <- cell_line\n",
    "    \n",
    "  beds[[cell_line]] <-beds[[cell_line]]  %>% GenomicRanges::makeGRangesFromDataFrame(\n",
    "                                            keep.extra.columns = T,\n",
    "                                            seqnames.field = \"V1\",\n",
    "                                            start.field = \"V2\",\n",
    "                                            end.field = \"V3\")\n",
    "  \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a51d88",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Plot un-normalized and normailzed distribtuion of scores\n",
    "\n",
    "all_peaks <- data.table::rbindlist(beds2)\n",
    "\n",
    "ggplot(all_peaks, aes(x=score,fill=cell_line)) + \n",
    "  geom_density(alpha=.4) + facet_grid(type ~ .) + xlim(0,400)\n",
    "\n",
    "ggplot(all_peaks, aes(x=score_scaled,fill=cell_line)) + \n",
    "  geom_density(alpha=.4) + facet_grid(type ~ .) + xlim(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858db4d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load the genes and create GRanges\n",
    "\n",
    "genesTrain <- data.table::fread(\"../ML4G_Project_1_Data/CAGE-train/X1_train_info.tsv\")\n",
    "genesVal <- data.table::fread(\"../ML4G_Project_1_Data/CAGE-train/X1_val_info.tsv\")\n",
    "genesTest <- data.table::fread(\"../ML4G_Project_1_Data/CAGE-train/X3_test_info.tsv\")\n",
    "\n",
    "genes <- rbind(genesTrain,genesVal) %>% \n",
    "  rbind(genesTest) %>%\n",
    "  GenomicRanges::makeGRangesFromDataFrame(\n",
    "    keep.extra.columns = T,\n",
    "    seqnames.field = \"chr\",\n",
    "    start.field = \"TSS_start\",\n",
    "    end.field = \"TSS_end\",\n",
    "    strand.field = \"strand\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f8e51",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# define gene set indices store in list for for loop\n",
    "\n",
    "train_and_val_inds <- which(genes$gene_name %in% c(genesTrain$gene_name,genesVal$gene_name))\n",
    "test_inds <- which(genes$gene_name %in% genesTest$gene_name)\n",
    "\n",
    "cell_line_gene_inds <- list(train_and_val_inds,\n",
    "                         train_and_val_inds,\n",
    "                         test_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557e38f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define the inner \"receptive field\"\n",
    "\n",
    "inner_rF <- 5000\n",
    "outer_rF <- 200000\n",
    "\n",
    "# Use the promoters function to expand the gene ranges around the TSS by +- rF\n",
    "\n",
    "shortIntevals <- promoters(genes,\n",
    "                          upstream  = inner_rF,\n",
    "                          downstream= inner_rF)\n",
    "\n",
    "longIntervals <- promoters(genes,\n",
    "                          upstream  = outer_rF ,\n",
    "                          downstream= outer_rF)\n",
    "\n",
    "# \n",
    "geneOverlaps <- findOverlaps(longIntervals,shortIntevals) %>%\n",
    "                as.data.frame()\n",
    "\n",
    "# Split single DF into list of DFs\n",
    "geneOverlaps <- split(geneOverlaps,f = geneOverlaps$queryHits)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ba8a4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "########################## CREATE FEATURES ##################################\n",
    "\n",
    "# Register the parallel backend\n",
    "\n",
    "num_cores <- 3\n",
    "registerDoParallel(cores = num_cores)\n",
    "\n",
    "\n",
    "res <- foreach(j = 1:3, .packages = c(\"dplyr\",\"GenomicRanges\")) %dopar% {\n",
    "  features  <- list() # Initialize features for cell line j\n",
    "  \n",
    "  shortOverlaps <- findOverlaps(shortIntevals,beds[[cell_lines[j]]]) %>%\n",
    "                   as.data.frame() %>%\n",
    "                   mutate(queryHits = factor(queryHits,levels = 1:length(genes))) %>%\n",
    "                   group_by(queryHits,.drop = FALSE) %>%\n",
    "                   group_split()\n",
    "  \n",
    "  LongOverlaps <- findOverlaps(longIntervals,beds[[cell_lines[j]]]) %>%\n",
    "                  as.data.frame() %>%\n",
    "                  mutate(queryHits = factor(queryHits,levels = 1:length(genes))) %>%\n",
    "                  group_by(queryHits,.drop = FALSE) %>%\n",
    "                  group_split()\n",
    "            \n",
    "  \n",
    "  for (i in cell_line_gene_inds[[j]]) {\n",
    "    \n",
    "    feature_bed <- numeric(178) # Number of features\n",
    "    \n",
    "    shortInteval <- shortIntevals[i]\n",
    "          \n",
    "    longInterval <- longIntervals[i]\n",
    "    \n",
    "    geneNeigbourhoodData <- shortIntevals[geneOverlaps[[i]]$subjectHits]\n",
    "    \n",
    "    shortRangeData <- beds[[cell_lines[j]]][shortOverlaps[[i]]$subjectHits] \n",
    "    \n",
    "    longRangeData <- beds[[cell_lines[j]]][LongOverlaps[[i]]$subjectHits]\n",
    "    \n",
    "    peaks_close_to_a_tssInds <- findOverlaps(geneNeigbourhoodData,longRangeData)\n",
    "    peaks_not_close_to_a_tssData <- longRangeData[-(peaks_close_to_a_tssInds@to)]\n",
    "    \n",
    "    offset <- 0\n",
    "    for (bed_file in bed_files) {\n",
    "      \n",
    "      peaks <- shortRangeData[shortRangeData$type ==  bed_file]\n",
    "      peaks_distal <- longRangeData[longRangeData$type ==  bed_file]\n",
    "      peaks_lonely_distal <- peaks_not_close_to_a_tssData[peaks_not_close_to_a_tssData$type ==  bed_file]\n",
    "      \n",
    "      feature_bed[1+offset] <- length(peaks) #number_of_peaks\n",
    "      feature_bed[2+offset] <- length(peaks_distal) - length(peaks) #number_of_distal_peaks\n",
    "      feature_bed[3+offset] <- length(peaks_lonely_distal) # number_of_distal_lonely_peaks\n",
    "\n",
    "      \n",
    "      if (feature_bed[1+offset] > 0) {\n",
    "\n",
    "\n",
    "        peak_centers <- (start(peaks) + end(peaks)) / 2\n",
    "        \n",
    "        center_dis <- peak_centers - ((start(shortInteval) + end(shortInteval))) / 2\n",
    "        feature_bed[4+offset] <- center_dis[which.min(abs(center_dis))] #distance_to_closest_peak_signed\n",
    "        feature_bed[5+offset] <- center_dis[which.max(abs(center_dis))] #distance_to_furthest_peak_signed\n",
    "        feature_bed[6+offset] <- min(abs(center_dis))                 # distance_to_closest_peak_unsigned\n",
    "        feature_bed[7+offset] <- sum(peaks$score) #sum_of_scores\n",
    "        feature_bed[8+offset] <- peaks[which.min(abs(center_dis)), ]$score #score_of_closet_peak\n",
    "        feature_bed[9+offset] <- peaks[which.max(abs(center_dis)), ]$score #score_of_furthest_peak\n",
    "        feature_bed[10+offset] <- max(peaks$score) #max_peak\n",
    "        feature_bed[11+offset] <- mean(peaks$score) #mean_peak\n",
    "        \n",
    "        # Binned Peak score sum vectors\n",
    "        \n",
    "        intervals <- seq(start(shortInteval),end(shortInteval) + 50,by=1000)\n",
    "        intervals[1]  <- intervals[1]  - 100000\n",
    "        intervals[11] <- intervals[11] + 100000\n",
    "        bincodes <- .bincode(peak_centers,intervals)\n",
    "        for (r in 1:length(peaks)) {\n",
    "          feature_bed[11+offset+bincodes[r]] <- feature_bed[11+offset+bincodes[r]] + peaks[r]$score\n",
    "        }\n",
    "        \n",
    "        \n",
    "      } else{\n",
    "        \n",
    "        feature_bed[4+offset] <- 1000000 #distance_to_closest_peak_signed\n",
    "        feature_bed[5+offset] <- 1000000 #distance_to_furthest_peak_signed\n",
    "        feature_bed[6+offset] <- 1000000 #distance_to_closest_peak_unsigned\n",
    "        feature_bed[7+offset] <- 0 #sum_of_scores\n",
    "        feature_bed[8+offset] <- 0 #score_of_closet_peak\n",
    "        feature_bed[9+offset] <- 0 #score_of_furthest_peak\n",
    "        feature_bed[10+offset] <- 0 #max_peak\n",
    "        feature_bed[11+offset] <- 0#mean_peak\n",
    "        \n",
    "      }\n",
    "      if (feature_bed[2+offset] > 0) {\n",
    "        feature_bed[22+offset] <- sum(peaks_distal$score) - feature_bed[7+offset] # sum_of_scores_distal\n",
    "        feature_bed[23+offset] <- feature_bed[22+offset]/feature_bed[2+offset] # mean_of_score_distal\n",
    "        # Add distance to closest distal peak ??? \n",
    "      } else {\n",
    "        feature_bed[22+offset] <- 0 # sum_of_scores_distal\n",
    "        feature_bed[23+offset] <- 0 # mean_of_score_distal\n",
    "      }\n",
    "      if(feature_bed[3+offset]> 0){\n",
    "        feature_bed[24+offset] <- max(peaks_lonely_distal$score) # lonely_distal_max\n",
    "        feature_bed[25+offset] <- mean(peaks_lonely_distal$score) # lonely_distal_mean\n",
    "      } else {\n",
    "        feature_bed[24+offset] <- 0 # lonely_distal_max\n",
    "        feature_bed[25+offset] <- 0 # lonely_distal_mean\n",
    "      }\n",
    "      offset <- offset + 25\n",
    "    }\n",
    "\n",
    "\n",
    "    feature_bed[176] <- (genes[i]$gene_end - genes[i]$gene_start) # gene_length\n",
    "    feature_bed[177] <- length(geneNeigbourhoodData) - 1 # number_of_genes_in_large_neighbourhood\n",
    "    feature_bed[178] <-  as.numeric(strand(genes[i]) == \"+\") # Strand\n",
    "    \n",
    "    \n",
    "    features[[genes[i]$gene_name]] <- feature_bed\n",
    "    \n",
    "  }\n",
    "  features\n",
    "}\n",
    "stopImplicitCluster()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe03b7e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create data.frames of the results THIS CODE IS KINDA DIRTYYYY\n",
    "\n",
    "# Load response vars\n",
    "\n",
    "train_vals_x1 <- data.table::fread(\"../ML4G_Project_1_Data/CAGE-train/X1_train_y.tsv\")\n",
    "train_vals_x2 <- data.table::fread(\"../ML4G_Project_1_Data/CAGE-train/X2_train_y.tsv\")\n",
    "\n",
    "validation_vals_x1 <- data.table::fread(\"../ML4G_Project_1_Data/CAGE-train/X1_val_y.tsv\")\n",
    "validation_vals_x2 <- data.table::fread(\"../ML4G_Project_1_Data/CAGE-train/X2_val_y.tsv\")\n",
    "\n",
    "features <- c(\"number_of_peaks\",\n",
    "              \"number_of_distal_peaks\",\n",
    "              \"number_of_distal_lonely_peaks\",\n",
    "              \"distance_to_closest_peak_signed\",\n",
    "              \"distance_to_furthest_peak_signed\",\n",
    "              \"distance_to_closest_peak_unsigned\",\n",
    "              \"sum_of_scores\",\n",
    "              \"score_of_closet_peak\",\n",
    "              \"score_of_furthest_peak\",\n",
    "              \"max_peak\",\n",
    "              \"mean_peak\",\n",
    "              paste0(\"bin_\",1:10),\n",
    "              \"sum_of_scores_distal\",\n",
    "              \"mean_of_score_distal\",\n",
    "              \"lonely_distal_max\",\n",
    "              \"lonely_distal_mean\"\n",
    ")\n",
    "\n",
    "\n",
    "feature_cols <- c()\n",
    "for (bed_file in bed_files) {\n",
    "  feature_cols <- c(feature_cols,paste0(features,\"_\",strsplit(bed_file,\"-bed\")[[1]]))\n",
    "}\n",
    "feature_cols <- c(feature_cols,\"gene_length\",\"number_of_genes_in_large_neighbourhood\",\"strand\")\n",
    "\n",
    "# GET DATA INTO RIGHT ORDER\n",
    "\n",
    "examine <- data.frame(res[[1]]) \n",
    "rownames(examine) <- feature_cols\n",
    "\n",
    "\n",
    "x1_feat <- data.frame(t(data.frame(res[[1]])))\n",
    "colnames(x1_feat) <- feature_cols\n",
    "\n",
    "rownames(x1_feat) <-  c(train_vals_x1$gene_name,validation_vals_x1$gene_name)\n",
    "x1_feat$y_val <- c(train_vals_x1$gex,validation_vals_x1$gex)\n",
    "\n",
    "\n",
    "x2_feat <- data.frame(t(data.frame(res[[2]])))\n",
    "colnames(x2_feat) <- feature_cols\n",
    "\n",
    "rownames(x2_feat) <-  c(train_vals_x2$gene_name,validation_vals_x2$gene_name)\n",
    "x2_feat$y_val <- c(train_vals_x2$gex,validation_vals_x2$gex)\n",
    "\n",
    "x3_feat <- data.frame(t(data.frame(res[[3]])))\n",
    "colnames(x3_feat) <- feature_cols\n",
    "rownames(x3_feat) <-  c(genesTest$gene_name)\n",
    "\n",
    "\n",
    "train_complete <-data.frame(rbind(x1_feat[train_vals_x1$gene_name,],\n",
    "                                  x2_feat[train_vals_x2$gene_name,]))\n",
    "\n",
    "val_complete <-data.frame(rbind(x1_feat[rownames(x1_feat) %in% validation_vals_x1$gene_name  ,],\n",
    "                                x2_feat[rownames(x2_feat) %in% validation_vals_x2$gene_name,]))\n",
    "\n",
    "test_complete <- x3_feat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c8bab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#make this example reproducible\n",
    "set.seed(0)\n",
    "\n",
    "# Test using only certain features\n",
    "train_complete<- train_complete %>%\n",
    "  select(-contains(\"H3K9me3\"))\n",
    "\n",
    "val_complete<- val_complete %>%\n",
    "  select(-contains(\"H3K9me3\"))\n",
    "\n",
    "train_complete<- train_complete %>%\n",
    "  select(-contains(\"H3K9me3\"))\n",
    "\n",
    "\n",
    "#define final training and testing sets\n",
    " \n",
    "\n",
    "xgb_train = xgb.DMatrix(data =  data.matrix(train_complete[,-ncol(train_complete)]),\n",
    "                        label = train_complete[,ncol(train_complete)])\n",
    "\n",
    "xgb_test = xgb.DMatrix(data = data.matrix(val_complete[,-ncol(val_complete)]),\n",
    "                       label = val_complete[,ncol(val_complete)])\n",
    "\n",
    "\n",
    "xgb_real_test = xgb.DMatrix(data = data.matrix(test_complete))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c3b53af",
   "metadata": {},
   "source": [
    "## Work Package 1.2 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f677b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Select the best model to predict gene expression from the obtained features in WP 1.1.\n",
    "\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "# Create XGboost watchlist to monitor the training\n",
    "\n",
    "watchlist = list(train=xgb_train, test=xgb_test)\n",
    "\n",
    "# Create a evalation function to use to montior the training\n",
    "\n",
    "evalerror <- function(preds, dtrain) {\n",
    "  labels <- getinfo(dtrain, \"label\")\n",
    "  err <- cor(labels , preds,method = \"spearman\")\n",
    "  return(list(metric = \"spearman\", value = err))\n",
    "}\n",
    "\n",
    "\n",
    "# Define a set of parameters to use (thse)\n",
    "\n",
    "param <- list(objective = \"count:poisson\",\n",
    "                          eval_metric = evalerror,\n",
    "                           subsample = 0.7,\n",
    "                           colsample_bytree= 0.4,\n",
    "                           lambda = 100,\n",
    "                           alpha = 750)\n",
    "\n",
    "# Train a XGboost model with the above parameters (monitor loss to find optimal nrounds)\n",
    "model = xgb.train(data = xgb_train,\n",
    "                  max.depth = 6,\n",
    "                  watchlist=watchlist,\n",
    "                  nrounds = 500,\n",
    "                  params = param)\n",
    "\n",
    "############################ HYPERPARAM SEARCH ####################################\n",
    "\n",
    "# Dumb grid search (DONT RUN)\n",
    "\n",
    "validation_pearsons <- list()\n",
    "\n",
    "for (max_depth in 4:7) {\n",
    "  for (alpha in c(1,250,500,750,1000)) {\n",
    "    for (colsample in c(0.3,0.4,0.5)) {\n",
    "      for (lambda in c(1,500,1000)) {\n",
    "  \n",
    "      \n",
    "      param <- list(objective = \"count:poisson\",\n",
    "                    eval_metric = evalerror,\n",
    "                    subsample = 0.7,\n",
    "                    colsample_bytree= colsample,\n",
    "                    lambda = lambda,\n",
    "                    alpha = alpha)\n",
    "      \n",
    "        model = xgb.train(data = xgb_train,\n",
    "                          max.depth = max_depth,\n",
    "                          watchlist=watchlist,\n",
    "                          nrounds = 500,\n",
    "                          params = param,\n",
    "                          verbose = 0)\n",
    "        validation_pearsons[[paste(max_depth,\n",
    "                             alpha,\n",
    "                             colsample,\n",
    "                             lambda)]] <- model$evaluation_log$test_spearman\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# best 6 750 0.4 1000 with 0.7817005\n",
    "\n",
    "losses_df <- data.frame(\n",
    "  iteration = 1:length(test_pearsons[[1]]),\n",
    "  stack(sapply(test_pearsons, `length<-`, max(lengths(test_pearsons))))\n",
    ")\n",
    "\n",
    "# Rename the columns\n",
    "colnames(losses_df) <- c(\"iteration\", \"iter\", \"hyperparameter\",\"loss\")\n",
    "\n",
    "# Plot the losses using ggplot2\n",
    "ggplot(data = losses_df, aes(x = iteration, y = loss, color = as.factor(hyperparameter))) +\n",
    "  geom_line() +\n",
    "  labs(title = \"Losses for Different Hyperparameters\",\n",
    "       x = \"Iteration\",\n",
    "       y = \"Pearsons on Validation Set\",\n",
    "       color = \"Max Depth\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Train optimal model with train and validation data\n",
    "\n",
    "train_and_val <- rbind(train_complete,val_complete)\n",
    "\n",
    "xgb_train_and_val = xgb.DMatrix(data =  data.matrix(train_and_val[,-ncol(train_and_val)]),\n",
    "                        label = train_and_val[,ncol(train_and_val)])\n",
    "\n",
    "\n",
    "final = xgboost(data = xgb_train_and_val,\n",
    "                max.depth = 6,\n",
    "                nrounds = 480,\n",
    "                params = param)\n",
    "\n",
    "# Look at feature importances \n",
    "\n",
    "feature_importance <- xgboost::xgb.importance(model = final)\n",
    "xgboost::xgb.plot.importance(feature_importance)\n",
    "#xgb.plot.shap(data.matrix(xgb_train_and_val[,-ncol(xgb_train_and_val)]), model = final,top_n = 10)\n",
    "#xgb.plot.shap.summary(data.matrix(xgb_train_and_val[,-ncol(xgb_train_and_val)]), model = final)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a346052",
   "metadata": {},
   "source": [
    "## Work Package 1.3 - Prediction on Test Data (Evaluation Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522fe8c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Using the model trained in WP 1.2, make predictions on the test data (chr 1 of cell line X3).\n",
    "# Store predictions in a variable called \"pred\" which is a numpy array.\n",
    "\n",
    "pred = None\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "# Write down the predicted values\n",
    "pred_y = predict(final, xgb_real_test)\n",
    "\n",
    "preds <- data.frame(\"gene_name\" = genesTest$gene_name,\n",
    "                    \"gex_predicted\" = pred_y,\n",
    "                    row.names = 0:(length(pred_y)-1))\n",
    "\n",
    "write.csv(preds,file = \"gex_predicted.csv\",row.names = T,quote = FALSE)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Check if \"pred\" meets the specified constrains\n",
    "assert isinstance(pred, np.ndarray), 'Prediction array must be a numpy array'\n",
    "assert np.issubdtype(pred.dtype, np.number), 'Prediction array must be numeric'\n",
    "assert pred.shape[0] == len(test_genes), 'Each gene should have a unique predicted expression'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "453b399e",
   "metadata": {},
   "source": [
    "#### Store Predictions in the Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6df835",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Store predictions in a ZIP. \n",
    "# Upload this zip on the project website under \"Your submission\".\n",
    "# Zip this notebook along with the conda environment (and README, optional) and upload this under \"Your code\".\n",
    "\n",
    "save_dir = 'path/to/save/output/file'  # TODO\n",
    "file_name = 'gex_predicted.csv'         # PLEASE DO NOT CHANGE THIS\n",
    "zip_name = \"LastName_FirstName_Project1.zip\" # TODO\n",
    "save_path = f'{save_dir}/{zip_name}'\n",
    "compression_options = dict(method=\"zip\", archive_name=file_name)\n",
    "\n",
    "test_genes['gex_predicted'] = pred.tolist()\n",
    "test_genes[['gene_name', 'gex_predicted']].to_csv(save_path, compression=compression_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
