{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that are required to run your project\n",
    "# You are allowed to add more libraries as you need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about data: \n",
    "- CAGE-train (\"data/CAGE-train\"): includes information about gene location and expression. X1 and X2 has train/val info/y, X3 only has test info that we should test on (only testing on chr1). \n",
    "- DNase-seq: information on chromatin accessibility (reads only in open chromatin)\n",
    "- bed, bigwig: genomic regions and associated annotations \n",
    "- do not use H3K9me3, distribution too different among X1, X2, X3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.1 - Modeling Choices & Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Load your feature (bed and/or bigwig and/or fasta) and target files (tsv) here.\n",
    "# Decide which features to use for training. Feel free to process them however you need.\n",
    "\n",
    "# NOTE: \n",
    "# bed and bigwig files contain signals of all chromosomes (including sex chromosomes).\n",
    "# Training and validation split based on chromosomes has been done for you. \n",
    "# However, you can resplit the data in any way you want.\n",
    "\n",
    "current_path = os.getcwd()\n",
    "path_data = current_path + \"/data/\"\n",
    "path_test = current_path + \"/data/CAGE-train/X3_test_info.tsv\"   \n",
    "test_genes = pd.read_csv(path_test, sep='\\t')\n",
    "\n",
    "# load bed files from separate files in a loop and store them in a list\n",
    "bedfiles = ['DNase-bed', 'H3K4me1-bed', 'H3K4me3-bed', 'H3K9me3-bed', 'H3K27ac-bed', 'H3K27me3-bed', 'H3K36me3-bed']\n",
    "bed_files_x1 = {}\n",
    "bed_files_x2 = {}\n",
    "bed_files_x3 = {}\n",
    "\n",
    "for i in bedfiles:\n",
    "    bed_files_x1[str(i)] = pd.read_csv(path_data + i + '/X1.bed', sep='\\t', header=None)\n",
    "    bed_files_x2[str(i)] = pd.read_csv(path_data + i + '/X2.bed', sep='\\t', header=None)\n",
    "    bed_files_x3[str(i)] = pd.read_csv(path_data + i + '/X3.bed', sep='\\t', header=None)\n",
    "\n",
    "# loading gene expression \n",
    "gex_path = 'CAGE-train'\n",
    "x1_train_info = pd.read_csv(path_data + gex_path + '/X1_train_info.tsv', sep='\\t')\n",
    "x1_train_y = pd.read_csv(path_data + gex_path + '/X1_train_y.tsv', sep='\\t')\n",
    "\n",
    "x1_val_info = pd.read_csv(path_data + gex_path + '/X1_val_info.tsv', sep='\\t')\n",
    "x1_val_y = pd.read_csv(path_data + gex_path + '/X1_val_y.tsv', sep='\\t')\n",
    "\n",
    "x2_train_info = pd.read_csv(path_data + gex_path + '/X2_train_info.tsv', sep='\\t')\n",
    "x2_train_y = pd.read_csv(path_data + gex_path + '/X2_train_y.tsv', sep='\\t')\n",
    "\n",
    "x2_val_info = pd.read_csv(path_data + gex_path + '/X2_val_info.tsv', sep='\\t')\n",
    "x2_val_y = pd.read_csv(path_data + gex_path + '/X2_val_y.tsv', sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "reach = 5000\n",
    "\n",
    "# extracting features from bed files and gene info data\n",
    "def extract_features(input_bed_files, gene_info):\n",
    "    # iterate through rows in gene_info \n",
    "    # return pandas dataframe with features\n",
    "\n",
    "    # create empty dataframe\n",
    "    features = pd.DataFrame()\n",
    "    for index, row in gene_info.iterrows():\n",
    "        chr = row['chr']\n",
    "        gene_length = row['gene_end'] - row['gene_start']\n",
    "        tss_start = row['TSS_start'] - reach\n",
    "        tss_end = row['TSS_start'] + reach\n",
    "        # loop through bed files\n",
    "        for j in bedfiles:\n",
    "            print(j)\n",
    "            bed_files = input_bed_files[j]\n",
    "            # filter bed files by chromosome\n",
    "            bed_files_filt = bed_files.loc[bed_files[0] == chr]\n",
    "            # print(bed_files_filt)\n",
    "            # select for rows that are within reach of TSS\n",
    "            bed_files_final = bed_files_filt[(bed_files_filt[1] >= tss_start) & (bed_files_filt[2] <= tss_end)]\n",
    "            # if bed_files_final not empty\n",
    "            if bed_files_final.size > 0:\n",
    "                if j == 'DNase-bed':\n",
    "                    score = bed_files_final[6]\n",
    "                else:\n",
    "                    # print(score)\n",
    "                    score = bed_files_final[4]\n",
    "                # peaks location \n",
    "                peak_start = bed_files_final[1]\n",
    "                peak_end = bed_files_final[2]\n",
    "\n",
    "                # sum of score\n",
    "                sum_score = score.sum()\n",
    "                # average score\n",
    "                avg_score = score.mean()\n",
    "                # max score\n",
    "                max_score = score.max()\n",
    "                # number of peaks\n",
    "                num_peaks = len(score)\n",
    "\n",
    "                # distance of tss midpoint to nearest peak midpoint\n",
    "                peak_midpoint = (peak_start + peak_end) / 2\n",
    "                tss_midpoint = (tss_start + tss_end) / 2\n",
    "                if num_peaks == 0:\n",
    "                    # arbtiary large distance if no peaks\n",
    "                    dist_to_peak = 2 * reach\n",
    "                else:\n",
    "                    # find index of peak which has midpoint closest to tss midpoint\n",
    "                    closest_peak = np.argmin(np.abs(peak_midpoint - tss_midpoint))\n",
    "                    # distance of tss midpoint to nearest peak midpoint\n",
    "                    dist_to_peak = np.abs(peak_midpoint[closest_peak] - tss_midpoint)\n",
    "            else:\n",
    "                sum_score = 0\n",
    "                avg_score = 0\n",
    "                max_score = 0\n",
    "                num_peaks = 0\n",
    "                dist_to_peak = 2 * reach\n",
    "        features = features.append({'gene_length': gene_length, 'sum_score': sum_score, 'avg_score': avg_score, 'max_score': max_score, \n",
    "                                        'num_peaks': num_peaks, 'dist_to_peak': dist_to_peak}, ignore_index=True)\n",
    "    features.set_index(gene_info['gene_id'], inplace=True)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNase-bed\n",
      "H3K4me1-bed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4g_project1/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4g_project1/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4g_project1/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/huijeong/Library/Mobile Documents/com~apple~CloudDocs/ETH Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# extract features for each dataset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x1_train_features \u001b[39m=\u001b[39m extract_features(bed_files_x1, x1_train_info)\n",
      "\u001b[1;32m/Users/huijeong/Library/Mobile Documents/com~apple~CloudDocs/ETH Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb Cell 6\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(input_bed_files, gene_info)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X35sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         closest_peak \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmin(np\u001b[39m.\u001b[39mabs(peak_midpoint \u001b[39m-\u001b[39m tss_midpoint))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X35sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         \u001b[39m# distance of tss midpoint to nearest peak midpoint\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X35sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         dist_to_peak \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(peak_midpoint[closest_peak] \u001b[39m-\u001b[39m tss_midpoint)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X35sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X35sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     sum_score \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4g_project1/lib/python3.8/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4g_project1/lib/python3.8/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4g_project1/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# extract features for each dataset\n",
    "x1_train_features = extract_features(bed_files_x1, x1_train_info)\n",
    "\n",
    "# print(bed_files_x1['DNase-bed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to subtract and add to tss region\n",
    "def tss_region(tss, start, end):\n",
    "    tss['TSS_start'] = tss['TSS_start'] - start\n",
    "    tss['TSS_end'] = tss['TSS_end'] + end\n",
    "    return tss\n",
    "\n",
    "# define a function to loop through bed files and extract signal sum in TSS region\n",
    "def extract_signal(bed_files, tss, features):\n",
    "    for i in tqdm.tqdm(bedfiles, desc= \"looping through bedfiles\"):\n",
    "        bed = bed_files[i]\n",
    "        chr = bed[0]\n",
    "        start = bed[1]\n",
    "        end = bed[2]\n",
    "        \n",
    "        if i == 'DNase-bed':\n",
    "            signal = bed[6]\n",
    "        else:\n",
    "            signal = bed[4]\n",
    "        for j in tss.index:\n",
    "            if any((chr == tss.loc[j, 'chr']) & (start >= tss.loc[j, 'TSS_start']) & (end <= tss.loc[j, 'TSS_end'])):\n",
    "                tss_signal = signal[(chr == tss.loc[j, 'chr']) & (start >= tss.loc[j, 'TSS_start']) & (end <= tss.loc[j, 'TSS_end'])].sum()\n",
    "            else:\n",
    "                tss_signal = 0\n",
    "            features.loc[j, i] = tss_signal\n",
    "        print(\"finished \" + i)\n",
    "        print(features.loc[:,i])\n",
    "    features = pd.DataFrame(features)\n",
    "    features.set_index(tss.index)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tss region\n",
    "tss_train = pd.DataFrame(x1_train_info[['gene_name', 'chr', 'TSS_start', 'TSS_end']])\n",
    "tss_train = tss_train.set_index('gene_name')\n",
    "tss_val = pd.DataFrame(x1_val_info[['gene_name', 'chr', 'TSS_start', 'TSS_end']])\n",
    "tss_val = tss_val.set_index('gene_name')\n",
    "tss_train = tss_region(tss_train, 5000, 5000)\n",
    "tss_val = tss_region(tss_val, 5000, 5000)\n",
    "\n",
    "tss_x3 = test_genes[['gene_name', 'chr', 'TSS_start', 'TSS_end']]\n",
    "tss_x3 = tss_x3.set_index('gene_name')\n",
    "tss_x3 = tss_region(tss_x3, 5000, 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "looping through bedfiles:   0%|          | 0/7 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/huijeong/Library/Mobile Documents/com~apple~CloudDocs/ETH Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m features_x2_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m features_x2_val \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m features_x1_train \u001b[39m=\u001b[39m extract_signal(bed_files_x1, tss_train, features_x1_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m features_x1_val \u001b[39m=\u001b[39m extract_signal(bed_files_x1, tss_val, features_x1_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m features_x2_train \u001b[39m=\u001b[39m extract_signal(bed_files_x2, tss_train, features_x2_train)\n",
      "\u001b[1;32m/Users/huijeong/Library/Mobile Documents/com~apple~CloudDocs/ETH Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb Cell 7\u001b[0m in \u001b[0;36mextract_signal\u001b[0;34m(bed_files, tss, features)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     signal \u001b[39m=\u001b[39m bed[\u001b[39m4\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m tss\u001b[39m.\u001b[39mindex:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39;49m((\u001b[39mchr\u001b[39;49m \u001b[39m==\u001b[39;49m tss\u001b[39m.\u001b[39;49mloc[j, \u001b[39m'\u001b[39;49m\u001b[39mchr\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m&\u001b[39;49m (start \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m tss\u001b[39m.\u001b[39;49mloc[j, \u001b[39m'\u001b[39;49m\u001b[39mTSS_start\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m&\u001b[39;49m (end \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m tss\u001b[39m.\u001b[39;49mloc[j, \u001b[39m'\u001b[39;49m\u001b[39mTSS_end\u001b[39;49m\u001b[39m'\u001b[39;49m])):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         tss_signal \u001b[39m=\u001b[39m signal[(\u001b[39mchr\u001b[39m \u001b[39m==\u001b[39m tss\u001b[39m.\u001b[39mloc[j, \u001b[39m'\u001b[39m\u001b[39mchr\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m&\u001b[39m (start \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m tss\u001b[39m.\u001b[39mloc[j, \u001b[39m'\u001b[39m\u001b[39mTSS_start\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m&\u001b[39m (end \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tss\u001b[39m.\u001b[39mloc[j, \u001b[39m'\u001b[39m\u001b[39mTSS_end\u001b[39m\u001b[39m'\u001b[39m])]\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huijeong/Library/Mobile%20Documents/com~apple~CloudDocs/ETH%20Zurich/2022-2023/ML4G/Project1/Project1_code.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# extract signal for x1 train, val, x2 train, val\n",
    "features_x1_train = pd.DataFrame()\n",
    "features_x1_val = pd.DataFrame()\n",
    "features_x2_train = pd.DataFrame()\n",
    "features_x2_val = pd.DataFrame()\n",
    "\n",
    "\n",
    "features_x1_train = extract_signal(bed_files_x1, tss_train, features_x1_train)\n",
    "features_x1_val = extract_signal(bed_files_x1, tss_val, features_x1_val)\n",
    "features_x2_train = extract_signal(bed_files_x2, tss_train, features_x2_train)\n",
    "features_x2_val = extract_signal(bed_files_x2, tss_val, features_x2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract signal for x3\n",
    "features_x3_test = pd.DataFrame()\n",
    "features_x3_test = extract_signal(bed_files_x3, tss_x3, features_x3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.2 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Select the best model to predict gene expression from the obtained features in WP 1.1.\n",
    "\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.3 - Prediction on Test Data (Evaluation Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Using the model trained in WP 1.2, make predictions on the test data (chr 1 of cell line X3).\n",
    "# Store predictions in a variable called \"pred\" which is a numpy array.\n",
    "\n",
    "pred = None\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Check if \"pred\" meets the specified constrains\n",
    "assert isinstance(pred, np.ndarray), 'Prediction array must be a numpy array'\n",
    "assert np.issubdtype(pred.dtype, np.number), 'Prediction array must be numeric'\n",
    "assert pred.shape[0] == len(test_genes), 'Each gene should have a unique predicted expression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Predictions in the Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in a ZIP. \n",
    "# Upload this zip on the project website under \"Your submission\".\n",
    "# Zip this notebook along with the conda environment (and README, optional) and upload this under \"Your code\".\n",
    "\n",
    "save_dir = 'path/to/save/output/file'  # TODO\n",
    "file_name = 'gex_predicted.csv'         # PLEASE DO NOT CHANGE THIS\n",
    "zip_name = \"LastName_FirstName_Project1.zip\" # TODO\n",
    "save_path = f'{save_dir}/{zip_name}'\n",
    "compression_options = dict(method=\"zip\", archive_name=file_name)\n",
    "\n",
    "test_genes['gex_predicted'] = pred.tolist()\n",
    "test_genes[['gene_name', 'gex_predicted']].to_csv(save_path, compression=compression_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
